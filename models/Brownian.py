# -*- coding: utf-8 -*-
"""
Created on Thu Feb  8 18:34:23 2024

@author: sebas
"""

import numpy as np
from numpy import cos,sin,arcsin,arctan2,arccos,sqrt,pi
from time import time
import sys
sys.path.append('../lib')

from sphere_exact import sample_exactBr

#%% Core functions,
# All points are on a sphere of center 0,0,0 and radius 1
# We use physical spherical coordinates azimuth is phi in [0,2*Pi] and elevation is theta in [0,Pi]
# The clusters coordinates lie on the upper hemisphere therefore theta is in [0,Pi/2]
# Clmuster mass is refered  here as mass.

def project(array):
    """ Orthogonal projection of all the points on the semi-sphere of radius 1 """
    return np.einsum("ij,i -> ij",array,1/np.sqrt(np.sum(array**2,axis = 1)))


def cartesian_to_spherical(x,y,z):
    theta = arccos(z)
    phi = arctan2(y,x) # equal to arctan(y/x) when x is not 0 and y>0, arctan(y/x) + pi when x not 0 and y <= 0. 
    return theta,phi

def spherical_to_cartesian(theta,phi):
    return sin(theta)*cos(phi),sin(theta)*sin(phi),cos(theta)

def tangent(array,dB2D):
    """ array = [n_clusters,3]
        subarray = [n_clusters,2]
        for $x$ in array, $y$ in subarray
        $X = [x,y,z]$, 3 dimensional array
        $Y = [y_1,y_2]$, 2 dimensional array
        
        Rotates $[y_1,y_2,0]$ in the plan tagent to the sphere at point $x$"""
    x,y,z = array[:,0],array[:,1],array[:,2]
    theta,phi = cartesian_to_spherical(x,y,z)
    ct,st,cp,sp = cos(theta),sin(theta),cos(phi),sin(phi)

    column1 = np.stack((-sp,cp,np.zeros(phi.shape)),axis = -1)
    column2 = np.stack((-ct*cp,-ct*sp,st),axis = -1)
    rotation_matrix = np.stack((column1,column2),axis = -1)
    # A = rotation matrix, ker(A) is of dimension 1 and generated by the unit norm orthogonal vector to the
    # tangent plane
    # returns A dB + array , affine transformation of the 2D Brownian increment which is equivalent to
    # a 2D Brownian increment in the Affine plan of parameters (ker(A),array)
    return np.einsum('nij,nj -> ni',rotation_matrix,dB2D) + array

def uniform_init(Npoints):
    """ Uniform repartition of polarisome proteins on the tip geometry"""
    #Z = np.random.rand(Npoints)*(1-radius0) + radius0
    Z = np.random.rand(Npoints)
    theta = np.arccos(Z)
    phi = -np.pi + 2*np.pi*np.random.rand(Npoints)
    return np.stack(spherical_to_cartesian(theta,phi),axis = 1)

def boundary(array):
    """ Treats the Boundary condition of points array that went out of the boundary"""
    z = array[:,2]# - radiuses
    ind = np.where(z<0)
    array[ind,2] =  - array[ind,2] #+ 2*radiuses[ind]

def reflected_brownian_sphere(array,sigmas,dt,switch):
    """ """
    n_clusters,_ = array.shape
    dtsigmas = dt*sigmas**2

    itangent = np.where(dtsigmas < switch)
    iexact = np.where(dtsigmas >= switch)
    res = np.zeros([n_clusters,3])

    array_tangent = array[itangent]
    array_exact = array[iexact]

    dB = sqrt(dt)*np.einsum("i,ij -> ij",sigmas[itangent], np.random.randn(array_tangent.shape[0],2))
    U = tangent(array_tangent,dB)
    U = project(U)
    res[itangent] = U
    if len(iexact[0])>0:
        res[iexact] = sample_exactBr(array_exact,dtsigmas[iexact])
    boundary(res)
    return res

        
#%% Funcions treating contact

def auxl(arr):
    """ For arr =[a1,a2,a3] returns the matrix [[a1 , a1 , a1]"""
    return np.tril(arr,k = -1).T
def auxu(arr):
    return np.triu(arr,k = 1)

def apply_to_couples_sumv2(arr,triu_indices):
    """ For arr =[a1,a2,a3] returns the array [a1 + a2, a1 + a3, a2 + a3]"""
    #arr1 = np.apply_along_axis(auxu,axis = 0,arr = arr)[triu_indices]
    #arr2 = np.apply_along_axis(auxl,axis = 0,arr = arr)[triu_indices]
    arr1 = np.tril(arr,k = -1).T[triu_indices]
    arr2 = np.triu(arr,k = 1)[triu_indices]
    return arr1 + arr2

def apply_to_couples_diffv2(arr,triu_indices):
    """ For arr =[a1,a2,a3] returns the array [a1 - a2, a1 - a3, a2 - a3]"""
    #arr1 = np.apply_along_axis(auxu,axis = 0,arr = arr)[triu_indices]
    #arr2 = np.apply_along_axis(auxl,axis = 0,arr = arr)[triu_indices]
    arr1 = np.tril(arr,k = -1).T[triu_indices]
    arr2 = np.triu(arr,k = 1)[triu_indices]
    return arr1 - arr2


def compute_cross_radius_cross_sigmas_squares_dist(array,radiuses,sigmas):
    """ Arguments:
            array : numpy ndarray, shape= (n_clusters,3)
            radiuses  : numpy ndarray, shape= (n_clusters)  
            sigmas  : numpy ndarray, shape= (n_clusters) 
        Returns:
            dist : numpy ndarray, shape= (n_clusters*(n_clusters-1)/2); For all diferent couples (X,Y) in array x array returns |X-Y|_2, where  X and  Y are in R^3.
            cross_radiuses : numpy ndarray, shape= (n_clusters*(n_clusters-1)/2); For all diferent couples (r_X,r_Y) in radiuses x radiuses returns r_X + r_Y
            cross_sigmas_squares : numpy ndarray, shape= (n_clusters*(n_clusters-1)/2); For all diferent couples (sigma_X,sigma_Y) in sigmas x sigmas returns (sigma_X)^2 + (sigma_Y)^2
            triu_indices : tuple( [numpy ndarray sahpe= (n_clusters*(n_clusters-1)/2)] ,[numpy ndarray sahpe= (n_clusters*(n_clusters-1)/2)] ); Indices of the non zero elements of a triangular superior matrix see numpy.triu  
    """
   
    n_clusters,_ = array.shape
    triu_indices = np.triu_indices(n_clusters,k=1)
    x, y, z = array[:,0], array[:,1], array[:,2]
    cross_x, cross_y, cross_z = apply_to_couples_diffv2(x,triu_indices), apply_to_couples_diffv2(y,triu_indices), apply_to_couples_diffv2(z,triu_indices)

    dist = np.sqrt(cross_x**2 + cross_y**2 + cross_z**2) # The distance between clusters 2 by 2

    cross_radiuses = apply_to_couples_sumv2(radiuses,triu_indices) # All the sums of the radiuses 2 by 2

    cross_sigmas_squares = apply_to_couples_sumv2(sigmas**2,triu_indices)
    return dist, cross_radiuses, cross_sigmas_squares,triu_indices

# Function handeling the construction of collision sets

def colliding_sets(I,J):
    """
        Two elements $i <j$ are in relation if i = I[k], j = J[k] for a given k.
        
    Arguments:
        I : list giving the i-indices ordered in non-increasing order.
        J : list giving the j-indices such that subsets $A_i = \lbrace J[k], I[k] = i \rbrace$ are ordered.
        Example:
            I = [0,0,0,1,1,3,4,4]
            J = [1,2,4,2,4,5,4,10]
    Returns:
        List of lists of element in a relation. By construction all lists are disjoint and of cardinal $\geq 2$
        For the previous example:
            [[0,1,2,4,10],[3,5]]
    """
    
    # Reccurcive function constructing each set
    # This algorithm
    def aux(level_set,I_var,J_var):
        """ Aguments:
                level_set : list_giving all the nodes at the current level 
                I_var : list giving the current i-indices of the collisions
                J_var : list giving the current j-indices of the collisions
            Returns:
                Total equivalence set containing all nodes in relations without repetitions
        """
        if len(level_set) == 0: # There is no new nodes in relation with the current level ie we reached the deepest level of the tree.
            return level_set
        else:
            new_level_set = []
            ind_in_level_set = 0
            n_var = len(I_var)
            while n_var > 0 and ind_in_level_set < len(level_set):
                i = level_set[ind_in_level_set]
                
                current_ind = 0
                to_remove = []
                while current_ind < n_var and I_var[current_ind] <= i:
                    j_current, i_current = J_var[current_ind], I_var[current_ind]
                    
                    if i_current == i and j_current not in new_level_set:
                        to_remove.append(current_ind)
                        if j_current not in level_set:
                            new_level_set.append(j_current)
                        else:
                            pass
                    elif j_current == i and i_current not in new_level_set:
                        new_level_set.append(i_current)
                        to_remove.append(current_ind)
                    else:
                        pass
                    current_ind += 1
                for removed_count, ind_to_remove in enumerate(to_remove): # We remove all k such we already visited the couple I[K],J[k]
                    I_var.pop(ind_to_remove - removed_count)
                    J_var.pop(ind_to_remove - removed_count)
                    n_var += -1
                ind_in_level_set += 1
            return level_set + aux(new_level_set,I_var,J_var)
                            
    I_var, J_var = list(I), list(J)
    n_var = len(I_var)
    sets = []
    while n_var > 0:
        total_set = aux([I_var[0]],I_var,J_var)
        sets.append(total_set)
        n_var = len(I_var)
    return sets

def handle_collisions(I,J,mass,active):
    if len(I) == 1:
        i, j = I[0], J[0]
        mass[j] = mass[i] + mass[j]
        mass[i] = 0
        active.pop(i)
    else:
        sets = colliding_sets(I, J)
        count_pops = 0
        for set_coll in sets:
            i0 = set_coll[0]
            mass_sum = mass[i0]
            for i in set_coll[1:]:
                mass_sum += mass[i]
                mass[i] = 0 
                active.pop(i - count_pops)
                count_pops += 1
            mass[i0] = mass_sum
    return mass

#%%
class Modelv3:
    """ Simulation of the Browninan Coalescence on the surface of a semi-sphere of radius 1 with reflective boundary conditions."""
    def __init__(self,n_clusters,sigmafun,radfun):
        r"""
        Arguments:
            n_clusters, integer : Number of initial clusters.
            sigmafun : Standard deviation function : $\sigma(x) = \sqrt{2D(x)}$ where $D$ is the diffusion function.
            radfun : Radius function.
        """
        self.n_clusters = n_clusters 
        self.sigf = np.vectorize(sigmafun) 
        self.radiusf = np.vectorize(radfun)
        
        self.active_masses = None
        self.active_sigmas = None
        self.active_radiuses = None
        
        self.dt = 0 # Adaptative time step

        self.times = None # shape = n_clusters
        self.masses = None # shape = n_clusters x n_clusters 
        
        self.active = [] # List of active clusters. It is initialized in the run method not here.
        self.trajectories = None # Tab of trajectories, only usfull for visual reprenstations.
        
        self.current_position = None # The current positions in cartesian coordiantes of the clusters.
        self.current_masses = None # The current masses of all clusters, the mass is a positive real value.
        
        self.sample_masses = None # 3d array n_samples x n_clusters x n_clusters, that the run method will save.
        self.sample_times = None # 2d array n_samples x n_clusters, second save of the run method.
        
        return None
    
    def _update_(self,tol,switch):
        """Updates cluster positions and handles collisionevents 
        Arguments:
            tol : The tolerance paramter  for estimating the probability of  missing a collision    
        """
        # Collection of arrays giving for each distinct couples (1,2) : |Z_1 - Z_2|, r1 + r2, sigma1^2 + sigma2^2 
        X = self.current_position[self.active,:]
        dist, cross_radiuses, cross_sigmas_squares,triu_indices = compute_cross_radius_cross_sigmas_squares_dist(X,self.active_radiuses,self.active_sigmas)
        # First step we test if there is any contact at the current step
        
        contact_indices_glob = np.where(dist < cross_radiuses) # The indices in the list of all couple
        #  operation retrieving indices of the colliding couples
        contact_indices_i,contac_indices_j = triu_indices[0][contact_indices_glob], triu_indices[1][contact_indices_glob]
            # If contact.
            # For n > 2 simultaneous collisions we remove n-1 clusters of the active list and the only remaing cluster mass is updated to the sum of
            # the n colliding masses. This treatment is done below: The loop is iterating thgrough an adjacence matrix where adjacent nodes are
            # the indices of colliding clusters.
        if len(contact_indices_i) > 0:
            mass = self.active_masses.copy()
            active = list(self.active)
            mass = handle_collisions(contact_indices_i,contac_indices_j, mass,active)
            self.current_masses[self.active] = mass #updates active cluster masses
            # mass = self.active_masses.copy()
            # for i,j in zip(contact_indices_i,contac_indices_j):
            #     mass[j] = mass[i] + mass[j]
            #     mass[i] = 0
            # self.current_masses[self.active] = mass #updates active cluster masses
            # popping active elements in contact_indices_i
            # popping active elements in contact_indices_i
            # for ki,i in enumerate(np.unique(contact_indices_i)):
            #     self.active.pop(i-ki) # We have to substract ki because the list self.active looses 1 element at each iteration.
            self.active = active
            self.masses[self.active,:] = np.tile(self.current_masses,(len(self.active),1))
        
            X = self.current_position[self.active,:]
            self.active_masses = self.current_masses[self.active]
            self.active_sigmas =  self.sigf(self.active_masses)
            self.active_radiuses =  self.radiusf(self.active_masses)

            dist, cross_radiuses, cross_sigmas_squares,triu_indices = compute_cross_radius_cross_sigmas_squares_dist(X,self.active_radiuses,self.active_sigmas)
        else:
            pass
        if len(self.active)> 1:

            self._adapt_dt_(tol,cross_sigmas_squares = cross_sigmas_squares,cross_radiuses = cross_radiuses,dist = dist)

            # updating position
            U = reflected_brownian_sphere(X,self.active_sigmas,self.dt,switch = switch)
            self.current_position[self.active,:] = U
            self.times[self.active] += self.dt #update the clocks of all active clusters 
        else:
            pass
        return None
        
    
    def _adapt_dt_(self,tol,cross_sigmas_squares,dist,cross_radiuses):
        """ Function adapting the time step to the current realtive cluster positions"""
        dt = np.min(((dist)**2/(2*cross_sigmas_squares)))* tol 
        if np.isnan(dt):
            print('===================================')
        self.dt = dt
        return None
        
    def run(self,Ntmax,n_samples = 1,stop = 1,tol = 1e-3,switch = 0.005,position_init = False,mass_init = False
            ,save_trajectories = False, save_name = None):
        """  Runs the model
        Arguments:
            Ntmax  :Maximum number of time iterations
            n_samples : Number  of sammples
            stop : Stops the runs when the  numlber of clustersis equal to stop
            tol : The tolerance paramter  for estimating the probability of  missing a collision    
            position_init : Initialisation of position if set on False the cluster are uniformly distributed on the sphere
            mass__init : Intialisation of the cluster masses if set  to False they each receive mass 1
            save_trajectories :  If set to True saves trajectories of the clusters, to do only for a very number of samples
            save__name : File name where to save results 
        Results saved as npy file:
            _times : numpy ndarray shape = (n_samples,n_clusters) ; For each sample gives all the collision times, the first column is zeros since there is n_clusters-1 collisions.
            _masses : numpy ndarray shape = (n_samples,n_clusters,n_clusters); For T =  _times[i,j] the time at sample  i and collision j, _masses[i,j,:]  is the cluster distribution at sample  i and collision number j.
        """
        print("Start of the run number of samples : "+str(n_samples))
        t0 = time()
        self.sample_masses = np.zeros([n_samples,self.n_clusters,self.n_clusters])
        self.sample_times = np.zeros([n_samples,self.n_clusters])
        for idi in range(n_samples):
            self.active = list(range(self.n_clusters))
            try: 
                # Traiter le cas ou on donne des sample et le cas ou on donne un vecteur !!!!
                shape = mass_init.shape
                if len(shape) == 1:
                    self.current_masses = mass_init.copy()
                else:
                    self.current_masses = mass_init[idi,:].copy()
            except:
                self.current_masses = np.ones([self.n_clusters])/self.n_clusters
            
            
            if position_init == 'center':
                Y0 = np.zeros([1,3])
                Y0[0,2] = 1
                self.current_position = np.concatenate((Y0,uniform_init(self.n_clusters-1)),axis = 0)
            elif position_init:
                self.current_position = position_init
            else:
                self.current_position = uniform_init(self.n_clusters)
            if save_trajectories:
                self.trajectories = [self.current_position[self.active]]
            else:
                pass

            # Initializing active varaibles
            # The active variables serve to store the values in memory instead of fetching them at each iteration.
            
            self.active_masses = self.current_masses
            self.active_sigmas =  self.sigf(self.current_masses)
            self.active_radiuses =  self.radiusf(self.current_masses)
            
            self.times = np.zeros([self.n_clusters])
            self.masses = np.tile(self.current_masses,(self.n_clusters,1))

            k = 0
            while k <= Ntmax and len(self.active) >stop:
                k = k + 1
                self._update_(tol,switch)
                if save_trajectories:
                    self.trajectories.append(self.current_position)
                else:
                    pass
            
            sorted_indices = np.argsort(self.times)
            temp = np.zeros([self.n_clusters])
            temp[1:] = self.times[sorted_indices][:-1]
            self.times = temp
            
            self.masses = self.masses[sorted_indices,:]
            self.sample_times[idi,:] = self.times
            self.sample_masses[idi,:,:] = self.masses
            print('\r',   'Advancement : %.1f'%(((idi+1)/n_samples)*100)+' %', 'done in %.2fs.' % (time() - t0),end='')
        print("End")
        print("Saving samples")
        if save_name:
            try:
                previous_save_masses = np.load(save_name+'_masses.npy')
                previous_save_times = np.load(save_name+'_times.npy')
                np.save(save_name+'_masses.npy',np.concatenate((self.sample_masses,previous_save_masses),axis = 0))
                np.save(save_name+'_times.npy',np.concatenate((self.sample_times,previous_save_times),axis = 0))
            except:
                np.save(save_name+'_masses.npy',self.sample_masses)
                np.save(save_name+'_times.npy',self.sample_times)
        else:
            pass
        return None
# When a cluster becomes inactive its clock stops naturally